\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\section{Graph theory}\footnote{ For a very simple introduction to graph theory, see \cite{Trudeau93}, for an advanced review of graph theory, see \cite{Bondy08}}
Formally a \emph{graph} $G$ is defined as $G = ( V(G), E(G) )$, with $V(G)$ designing the vertex set ( the points or nodes ) of $G$ and $E(G)$ as $E(G) \subseteq \{ \{x, y\}, x, y, \in V(G), x \neq y \}$, the set of edges ( the lines ) of G. 
\newline
This is the simplest way to define a graph, hence this kind of graph is usually called a \emph{simple graph}. 
More general graphs can be defined, for instance the loopy graphs, multigraphs, directed graphs or hypergraphs. 
They are not of major importance in this report so they won't be detailed here, their formal definition can be found in any book on graph theory ( see for instance \cite{Bondy08} ).
\newline
We will call two vertices $u, v \in V(G)$ as \emph{adjacent} if $\{u, v\} \in E(G)$ and we will write it as $u \leftrightarrow v$. 
We may also refer to edges being adjacent if they share a vertex.
\newline
As an example of a graph we can consider the following graph (TODO: ADD GRAPHICAL REPRESENTATION) with $ V(G) = \{a, b, c, d, e\}, E(G) = \{e_1,e_2, e_3, e_4, e_5, e_6, e_7\}$ with : 
\begin{align*}
	e_1 = \{a, b\}\quad
	e_2 = \{a, c\}\quad
	e_3 = \{b, c\}\quad
	e_4 = \{a, d\}\\
	e_5 = \{c, d\}\quad
    	e_6 = \{a, e\}\quad
	e_7 = \{c, e\}
\end{align*}
The \emph{adjacency matrix} of a graph $G$ is the $n \times n$ matrix defined as $A_G = (a_{u,v})$ with $a_{u, v} = \mathbbm{1}_{E(G)}(\{u, v\})$
\begin{equation}
	A_G = \kbordermatrix{
		  & a & b & c & d & e \\
		a & 0 & 1 & 1 & 1 & 1 \\ 
		b & 1 & 0 & 1 & 0 & 0 \\ 
		c & 1 & 1 & 0 & 0 & 1 \\ 
		d & 1 & 0 & 0 & 0 & 0 \\ 
		e & 1 & 0 & 1 & 0 & 0 \\ 
	}
\end{equation}

It is interesting to note that an adjacency matrix is real and hermitian, thus all of its eigenvalues are real and the study of their distribution is a classical topic in graph theory.
\newline
An important property of graphs is the \emph{degree} of the vertices, so we will denote by $d_G(v)$ the number of edges incident with $v \in V(G)$.
Observing that each edge has two ends and that the degree of a vertex is the number of edges having this vertex as an end. We obtain :
\begin{equation}
	\sum_{v\in V(G)} d_G(v) = 2 |E(G)|
\end{equation}
We also call the degree sequence the non-increasing sequence of its vertex degrees.
And we can also define the two following notations that will prove useful in the following of this report, $\delta(G)$ as the minimal degree of $G$ and $\Delta(G)$ as the maximal degree of $G$.
\newline
We define a \emph{path} on a graph as a sequence of edges being two by two adjacent. 
One of the most fundamental properties of graphs is also the connectivity.
We will say that a graph is \emph{connected}, if there is a path connecting any two edges. 
In fact we will consider simple\footnote{ More generally, the use of the adjective \emph{simple} denotes that we study something without loop or multi-edge}  paths because we are studying simple graphs.
It is clear that if a path exists it is always possible to extract a simple path from it.
There are two famous kinds of path, the \emph{hamiltonian path}, it is a path that includes all vertices of $G$. Analogously, an \emph{Eulerian path} is a path in which all edges are used exactly once.
\newline
If $v$ is a vertex, we will write $N(v)$ the set of vertices adjacent to $v$ called the \emph{neighbours} of $v$.
From this definition we may observe that $d_G(v) = |N(v)|$ if $G$ is a graph without loops. 
And we will call a (connected) \emph{component} of a vertex the set of vertices that can be reached from this vertex. 
Then a connected graph is a graph with only one component.
\newline
Some interesting graphs to which we will often refer are the complete graph on n vertices, denoted by $K_n$, and the complete bipartite graph $K_{n,m}$ (TODO : ADD GRAPHICAL REPRESENTATION ). 
A \emph{complete graph} is a graph in which for any vertex, the set of neighbours is the rest of the graph. 
A graph is \emph{bipartite} if it's set of vertices can be partitioned in two subsets $X$ and $Y$ such that every edge has one end in $X$ and one in $Y$. 
The \emph{complete bipartite graph} is a bipartite graph such that for all $x \in X$ we have $N(x) = Y$. 
This implies the same condition on the vertices in $Y$.
We will also call a \emph{cycle}, of size $n \geq 3$, denoted $C_n$ a graph whose vertices can be arranged in a cyclic sequence in such a way that two vertices are adjacent if they are consecutive in the sequence.
\newline
As there is usually no confusion possible we will denote $V = V(G), E =E(G), \psi = \psi_G, ...$. 


\section{Random graphs}
The study of random graphs is a flourishing area of mathematics since it's founding papers have been published by Erd\H{o}s and Renyi between 1959 and 1963 \cite{erdos59} \cite{erdos60} \cite{erdosconnect61} \cite{erdosevol61} \cite{erdos63}).
(TODO : REVISE THIS WHOLE SECTION )
Since then a lot of work has been done on random graphs, most of the questions on the Erd\H{o}s-Renyi model have found satisfying answers, and the model being simplistic, many new models have been developed.
So we will use the very vague definition by Janson \cite{Janson14}.
\begin{definition}
	A \emph{random graph} is a graph where nodes, or edges, or both are selected by a random procedure.
\end{definition}
More formally, a random graph is a probability distribution on a space of graphs.
This means that when studying random graphs, we can not only change the distribution but also the space in which we sample.
\newline
Usually we make the choice of sampling on a space of graphs containing any graph with a specified number of vertices.
\footnote{This choices differs from what usually appear in the real-world where networks are grown through time, see \cite{CHKNS01} for a discussion on fundamental differences between grown random graphs and the static random graphs.}
Some restrictions on this space might be done, for instance by selecting graphs with each vertex of the same degree ($r$-regular random graphs), or with the degree sequence following a specific distribution ( like the Newman-Strogatz-Watts model \cite{Newman01}, \cite{Newman02} ).
Sometimes random graphs are developped in order to produce a sampling space matching  some particular phenomenom observed in real-world networks.

For instance in social networks, two persons having a friend in common are likely to be friends which in the vocabulary of graph theory indicates the presence of a triangle.
For this purpose was developped the Watts-Strogatz small world model \cite{WattsStrogatz98} which has a large enough number of triangle. 
\footnote{More formally, a positive density of triangles}
It also features a "small world" characteristic meaning that for most of the vertices there exists a path linking them which is small enough.
\newline

\section{Cayley's formula}
This section will first of all demonstrate an important result that will be used several times in crucial demonstrations in this report. Although it is not a demonstration that is specific to random graphs it may give an insight to the variety of techniques that may be used in the study of random graphs and how elegant are the results ( at least quite often ). This formula has been demonstrated in many different ways and we will use the demonstration by Joyal \cite{joyal} \footnote{In fact we follow the procedure from \cite{JoyalProof} that is obtained from \cite{joyal} }that is really elegant and also is a good place to introduce several notions that will be used in the rest of the report. 
\begin{theorem}{Cayley's formula}\label{cayley}
\begin{equation}
    t_n = n^{n-2}
\end{equation}
with $t_n$ the number of spanning trees on $n$ vertices.
\end{theorem}
Before beginning the proof some definitions will be needed. A structure ( graph or tree ) is called \emph{spanning} on the vertices (resp. edges ) if it intersects all vertices (resp. edges). 
A \emph{tree} is a special case of graph structure, that can be defined in several equivalent ways. For instance, a tree is a connected graph such that upon removal of any of it's edges it becomes disconnected, equivalently, it's a graph in which every two vertices are linked by exactly one path, equivalently, it's a connected and acyclic graph ( doesn't contain any cycle ).
\newline 
The trees being a subset of the graphs, it is also possible to define \emph{directed trees} in which you can follow an edge only in one direction ( otherwise it would not be a tree anymore ).
We also define doubly rooted trees as trees with two special labels "Start" and "End" that can be attached to any vertices of the tree and which canonically maps on each edges the direction such that any vertex can reach the end. And we will call "SEL" the vertices that are in the "Start" to "End" line. 
We also denote by $DRT_n$ the set of doubly rooted trees on n vertices.
\newline
As a consequence of this definition we have $|DRT_n| = n^2 t_n$. With $|\ |$ denoting the cardinal. 
To prove the theorem it would then be sufficient to prove that the number of elements in $DRT_n$ is equal to $n^n$. So we will base our approach on Joyal's proof and show a bijection between the set of doubly rooted trees on n vertices and the the set of functions on $n$ elements.
(TODO : ADD GRAPHICAL REPRESENTATION OF THE PROOF ON SOME EXAMPLE)
\begin{proof}
We will use the notation $[n] = \{1, 2, ..., n\}$ and $V = [n]$.
Let's take $f:V \longrightarrow V$, and let's consider the graph of $f$. That is, $\forall v_1, v_2 \in V$ we have $v_1 \rightarrow v_2$ if and only if $f(v_1) = v_2$.
Drawing such a graph for any function, and will appear two different kind of structures, first there will have directed line leading to cycles, and then cycles. 
And the whole graph will be a disjoint union of such components.
It can be interesting to observe the case in which $f$ is a permutation and then observe that the graph of $f$ is a union of disjoint cycles as expected from the common group theory result.
\newline
We now take $C \subseteq V$ the set of vertices that are part of a cycle under the action of $f$. Equivalently,
\begin{align*}
    C = \{ x : \exists i \geq 1 s. t. f^i(x) = x \}
\end{align*}
Let $k = |C|$ and write $C_<$ as $C_< = \{c_1 < c_2 <...<c_k\}$ the ordered set and now we will construct a graph with the vertex set $D = f(C)$, and the edge set $E = \bigcup_{i=1}^{k-1} f(c_i)f(c_{i+1})$. We now have $G=(D, E)$ as a line of $k$ vertices, and we will call $f(c_1)$ the "Start" and $f(c_k)$ the "End".
\newline
Now we will just append to this line the set of vertices that are not in $G$. So we construct $\tilde{E} = \bigcup_{x \in V\\C} x f(x)$ and $\tilde{G} = (V, E\cup\tilde{E})$ is a (directed doubly rooted) tree as it doesn't contain any cycle by construction and is clearly connected. It's obviously directed and  doubly rooted.
We have now done the biggest part of the proof, that is, going from a function to a doubly rooted tree.
\newline
We will now take a doubly rooted tree and transform it in a function. From the definition of trees there is a unique "Start" to "End" ( SEL ) path.
\newline
For vertices on not on the SEL, for instance some vertice $j$, we define $f(j)$ as the first neighbour on the $j$ to end line.
\newline
For vertices on the SEL, 
\begin{align}
    SEL = \{x_1, x_2, ..., x_k\}, \text{ and } SEL_< = \{x_{\sigma_1}, x_{\sigma_2}, ..., x_{\sigma_k}\} 
\end{align}
we define $f(x_{\sigma_i}) = x_i, \forall i \in [k]$.
\newline
Thus, we have two injective constructions, if composed give the identity, hence we have a bijection between the set of endomorphism of $[n]$ and the space of doubly rooted trees on n vertices. So the proof is complete.
\end{proof}
