\section{Different approaches of the same space}
As said in the title of the section there are different ways to approach the Erd\H{o}s-Renyi model that we may call paradigms as they will give us the same kind of results but depending on the context, one might be much more convenient to use than the others.
\newline
The first paper published on random graphs that gained notoriety was from Erd\H{o}s and Renyi in 1959 \cite{erdos59}, in which they give the following construction :
\begin{definition}
We call a random graph $\mathcal{G}_{n, M}$ having $n$ labelled vertices and $M$ edges. That is we choose at random ( with equal probability ) one of the $\binom{\binom{n}{2}}{M}$ possible graphs.
\end{definition}
One may observe that some changes in notations are made between this paraphrasing of the article of Erd\H{o}s and Renyi, they are made in order to be more adapted with the modern study of random graphs. We will also adopt for the following $N = \binom{n}{2}$ to denote the total number of edges possible on $n$ labelled vertices.
\newline
We then arrive to our main model that has been the most extensively studied in the literature of random graphs, that is $\mathcal{G}_{n, p}$ on which the coin tosses are no longer necessarily fair, but the probability of drawing an edge is now $p$.
This model was first introduced by Gilbert in 1959, see \cite{Gilbert59}\footnote{It is interesting to note that Gilbert's paper who was at the time working at Bell's laboratories formulated the question of connectivity based on real life phone networks.}.
And the coin tosses are still independent. Now if we denote by $e_G$ the number of edges of a graph $G$ on the vertex set $[n]$. We have :
\begin{align}
	\mathbb{P}(G) = p^{e_G}(1-p)^{N-e_G}
\end{align}
This model is called the \emph{binomial model}. It is easily seen that this model is asymptotically equivalent to the first one if $Np$ is close to $M$ on several aspects.
\newline
The third model that we will investigate is on the form of a Markov process, see in Annex for a discussion on properties used here from Markov chains. 
At time 0 there is no edge and an edge is selected at random among all of the possible edges. 
At time $t$, the edge is chosen among all the edges not already present in the graph. We denote this process by $\{\mathcal{G}_{n, t}\}_t$, with $t$ the number of edges added. 
It is clear that this model is perfectly equivalent to the first model presented in the case $t = M$. 
This model was also introduced in 1959 by Erd\H{o}s and Renyi and is usually referred to as the \emph{random graph process}.
The advantage of this model is that it allows one to study properties on the verge of their realisations.
For instance, using this model Bollob\'as and Thomason \cite{Bollob85} proved that a graph is fully connected, when the last connection made is between an isolated vertices and the giant component. Equivalently, when $\delta(G) > 1$. But we will study this in the following.
\newline
The three models introduced above ( $\mathcal{G}_{n, M}$, $\mathcal{G}_{n, p}$ and $\{\mathcal{G}_{n, t}\}_t $) are usually designated in the literature as Erd\H{o}s-R\'enyi model.
However, even if the first two are quite similar (static random graphs) the last one is of a different nature as it is dynamic.
\newline
In this report we will mainly focus on $\mathcal{G}_{n, p}$ which is in fact easier to study than $\mathcal{G}_{n,M}$.
\footnote{There is usually no confusion possible on the model being studied.}
We will see in \eqref{th:linkMP} that there is a strong relation between those two models.

\section{Connectivity}

One of the most fundamental structure of a graph will be its number of components. 
Hence, the first question we will try to ask is with which probability a random graph in the Erd\H{o}s-Renyi model is connected. 
It is essential to answer this question as many other questions might not make sense or have an obvious answer on a graph that is not connected ( for instance the diameter, the existence of Hamiltonian paths or the stability number of the graph ). 
\newline
It is also an interesting first topic to have an insight of the kind of elegant results that arise from the study of random graphs.
The main aim of this section will be to prove the following theorem in a detailed way as it is the first random graphs proof that we will study.
\begin{theorem}\label{th:connect}
	Let $p = p(n) = \frac{\log(n) + c}{n}$ , $c \in \mathbb{R}$
\newline
Then $\lim_{n \to \infty} P(G \in \mathcal{G}_{n, p}\text{ is connected }) = e^{-e^{-c}}$ 
\end{theorem}
The proof of this theorem will be in two parts, first we will show that a graph will be connected if and only if there are no isolated vertices and then we will estimate the distribution that follows the number of isolated vertices.
We designate by giant component a component with a size increasing linearly in $n$.
\begin{theorem}\label{th:isolcomp}
	With $p = \frac{\log(n) + c}{n}$
	 Almost every $G \in \mathcal{G}_{n, p}$ consists of a single giant component and isolated vertices. 
\end{theorem}
\begin{proof}
This proof can be found in \cite{Spencer14} or \cite{Bollob01}.
\newline
During this proof we will consider the random value $X_k$ that counts the number of vertices that are in components of size $k$.
So, let's estimate the probability $P(X_2 > 0) = P(X_2 \geq 1 )$. In order to do so we will use the method of first moment.
\begin{align}
	\mathbb{P}(X_2 \geq 1) \leq \mathbb{E}(X_2) 	&= \binom{n}{2}\mathbb{P}(\text{"drawing an isolated edge"}) \\
						    	&= \binom{n}{2}p((1-p)^{n-1})^2 \\
							&\leq (\frac{ne}{2})^2p(e^{-p})^{2(n-2)} \\
						    	&= \mathcal{O}\left(n^2p \frac{ e^2 e^{-2p(n+1)} }{4}\right) \\
							&= \mathcal{O}(n^2p)
\end{align}
So it's sufficient that $p = o(n^{-2})$ in order to have almost surely no edges in G. This is clearly satisfied by the $p$ we use in the theorem.
\newline
However, this is not sufficient to prove that there is no isolated component other than isolated vertices. We will observe that there can't have any component of size larger than $\lceil \frac{n}{2} \rceil$ that is not the largest component in the graph.
Hence, we will study the probability that there is any component of intermediary size that is not the greatest component.
\begin{align}
	\mathbb{P}(X_k \geq 1) &\leq \mathbb{E}(X_k)\quad, \forall k \geq 3 \\
				&\leq \binom{n}{k} k^{k-2} q_k\\
				&\leq \binom{n}{k} k^{k-2} p^{k-1} ((1-p)^{n-k})^k
\end{align}
In the above, $q_k$ represents the probability that a spanning tree on $k$ vertices doesn't connect to the greatest connected components, the total number of spanning trees on $k$-vertices being $k^{k-2}$ from Cayley's formula \eqref{cayley}.
A tree on $k$ vertices having $k-1$ edges, this means in terms of probability that it must have $k-1$ "success" and on each of the $k$ vertices $n-k$ failures. Which leads to the following line.
\newline 
Now we will try to have an upper bound of the RHS such that the sum on $k$ will converges to a $o(n^{-\delta})$ for some $\delta >0$.
\begin{align}
	\mathbb{P}(X_k \geq 1) 	
	            &\leq k^{-2}p^{-1}(\frac{ne}{k})^k k^{k} p^{k} e^{-p\frac{n}{2}(n-k))}\\
	            &\leq k^{-2}p^{-1}((\frac{ne}{k}) k p e^{-p\frac{n}{2}})^k\\
	            &\leq p^{-1}(nep e^{-p\frac{n}{2}})^k
\end{align}
If we denote the bracketed term by $A$, then
\begin{equation}
    A = \mathcal{O}(\log(n) n^{-\frac{1}{2}})
\end{equation}
Hence, $A$ goes to 0 without any condition on $k$, so we obtain
\begin{equation}
    \sum_{k=3}^{\lceil n/2\rceil} \mathbb{P}(X_k \geq 1)\leq p^{-1}\sum_{k=3}^{\lceil n/2\rceil} A^k = o(1)
\end{equation}
This gives the fact that whether $\mathcal{G}_{n,p}$ is connected doesn't depend on the existence of isolated connected components of size 2 or more. So it only depends on the existence of isolated vertices.
So we have proved \eqref{th:isolcomp}.
\end{proof}

The proof of \eqref{th:connect} can be done using the second moment method or Stein's method, see \cite{JLR}. (TODO : CHOOSE WHICH ONE TO PRESENT.).


\section{Existence of thresholds}\footnote{ The proofs and results from this section are from \cite{JLR} and \cite{Bollob01}}
One of the most surprising features on random graphs, which seems to have motivated Erd\H{o}s to publish his results from 1959 ( TODO : FIND THE REF THAT SAID THAT...), is the existence of thresholds.
Indeed the property of appearance of certain graph properties will be either 0 or 1 for a great range of functions $p$.
\newline
For instance from the previous theorem we observe that $\forall \epsilon > 0$  if $p = (1+\epsilon)\frac{\log(n)}{n}$ 
or if $p = \frac{\log(n) + \omega(n)}{n}$ with $\lim_{n\to \infty} \omega(n) = \infty$ then $\lim_{n\to\infty}\mathbb{P}(G \in \mathcal{G}_{n,p} \text{is connected}) = 1$.
We would say that for such $p$, $\mathcal{G}_{n,p}$ is almost surely connected.
We also observe that if in the previous definitions of $p$ we changed the $+$ signs into $-$ signs, we would find that $\mathcal{G}_{n,p}$ is almost surely disconnected.
\newline
Hence, the function $p$ from \eqref{th:connect} has some very peculiar behaviour on the property of connectivity.
We will call such a function a \emph{threshold} (here, for connectivity).
\newline
The aim of this section is to detail formally what we mean by a graph property and a threshold function.
We will also show a formal relation between $\mathcal{G}_{n,p}$ and $\mathcal{G}_{n,M}$ and a proof of the existence of thresholds on a family of graph properties.
\newline
It has been shown by Bollob\'as and Thomason \cite{Bollob87} that this is in fact not exclusive to random graphs, but true for all monotone properties on random subsets.
\begin{definition}
	We will call a \emph{graph property} a family of graphs that is closed under isomorphism.
\end{definition}
This means that a graph property is independent of the labelling and of the drawing of the graph.
We can refine properties in the following definition.
\begin{definition}
	A property is \emph{monotone }\footnote{ A property is monotone if it is either increasing or decreasing} \emph{increasing} (resp. \emph{decreasing}) if it's stable under the the addition (resp. removal) of an edge.
	A graph property $\mathcal{Q}$ is \emph{convex} if when $ A,C \in \mathcal{Q}$ and $A\subseteq B\subseteq C$\footnote{ $\subseteq$ is the inclusion of the edges on the same set of vertices} then $B \in \mathcal{Q}$. 
\end{definition}

For instance, being connected or containing a specific subgraph are monotone increasing properties whereas being planar or containing an isolated vertex are monotone decreasing. 
As an example of property that is neither monotone increasing or decreasing, we can think of being $k$-regular for some $k$ ( this means that all vertices are of degree $k$).
Having exactly $k$ isolated vertices is an example of a convex not monotone property.
\newline
Here is a theorem showing that monotone increasing properties make probability distributions on these properties also monotone increasing.
\begin{theorem}\label{th:QIncr}
	Suppose $\mathcal{Q}$ is a monotone increasing property and $0 \leq M_1 \leq M_2 \leq N$ and $0 \leq p_1 \leq p_2 \leq 1$.
	\newline
	Then
	$$\mathbb{P}_{M_1}(\mathcal{Q}) \leq  \mathbb{P}_{M_2}(\mathcal{Q}) \text{  and  } \mathbb{P}_{p_1}(\mathcal{Q}) \leq \mathbb{P}_{p_2}(\mathcal{Q})$$
\end{theorem}
\begin{proof}
	The first inequality is clear, as the only difference between the two spaces on which we evaluate the property $\mathcal{Q}$ is that on the RHS edges have been added, hence, the probability of realising a monotone increasing has been increased.
	\newline
	For the second inequality, let $p = \frac{p_2 - p_1}{1 - p_1}$. Let $G_1 \in \mathcal{G}_{n, p_1}, G_2 \in \mathcal{G}_{n, p}$
	\newline
	So if $G_2 = G_1 \cup G$ it's edges are chosen with probability $p_1 + p - p_1 p = p_2$. So $G_1$ is in $G_2$, the property being monotone increasing, we have $ \mathbb{P}_{p_1}(\mathcal{Q}) \leq \mathbb{P}_{p_2}(\mathcal{Q})$
\
\end{proof}
The following result follows from definition with $\mathcal{Q}$ a monotone increasing property
\begin{equation}\label{eq:QProp}
	\mathbb{P}(\mathcal{Q}) = \sum_{A \in \mathcal{Q}} p^{|A|}(1-p)^{N-|A|}
\end{equation}
However this result requires to know all of the elements in $\mathcal{Q}$ and as we are often interested with properties for very large $n$ this result won't be magical... 
\newline
The following theorem shows that if we know quite accurately $\mathbb{P}_M(\mathcal{Q})$ for every $M$ close to $pN$ then we know $\mathbb{P}_p(\mathcal{Q})$ with a comparable accuracy. The converse being clearly false, for instance the property of containing M edges.

\begin{theorem}\label{th:linkMP}
	Suppose $\mathcal{Q}$ is any property and $0 < p = M/N< 1$ 
	\newline
	Then $\mathbb{P}_M(\mathcal{Q}) \leq 3 \sqrt{M}\mathbb{P}_p(\mathcal{Q})$
\end{theorem}
\begin{proof}
	Let $\mathcal{Q}$ be any property, then we will write $\mathcal{Q}$ as a partition based on the number of edges in each graph contained in $\mathcal{Q}$.
	\newline
	So we have
	$$\mathcal{Q} = \bigsqcup_{m=0}^{N} \mathcal{Q}_m \quad, \text{ with } \forall G \in \mathcal{Q}_m, e(G) = m$$
	$\mathbb{P}_m(\mathcal{Q}) = |\mathcal{Q}_m| \binom{N}{M}^{-1}$
	From this we can obtain, with $q = 1 - p$
	\begin{align*}
		\mathbb{P}_p(\mathcal{Q})	&= \sum_{A \in \mathcal{Q}} p^{|A|}q^{N-|A|}
						= \sum_{m=0}^{N}\sum_{A \in \mathcal{Q}_m} p^{|A|}q^{N-|A|}\\
						&= \sum_{m=0}^{N}\sum_{A \in \mathcal{Q}_m} p^{m}q^{N-m}
						= \sum_{m=0}^{N}|\mathcal{Q}_m|p^{m}q^{N-m}\\
						&= \sum_{m=0}^N p^mq^{N-m}\binom{N}{M}\mathbb{P}_m(\mathcal{Q}) 
						\geq \binom{N}{M}p^Mq^{N-M}\mathbb{P}_M(\mathcal{Q}) \\
						&\geq \mathbb{P}_M(\mathcal{Q})(e^{\frac{1}{6M}}\sqrt{2\pi p q N})^{-1}\\
	\end{align*}
	So we have \eqref{binomTail} (TODO : PROVE LAST INEQ IN ANNEX OR ADD REF )
	\begin{equation}
		\mathbb{P}_M(\mathcal{Q}) \leq  \mathbb{P}_p(\mathcal{Q})e^{\frac{1}{6M}}\sqrt{2\pi q M}
	\end{equation}
	Observing that $q \leq 1$ and $\sqrt{2\pi}e^{\frac{1}{6}} \approx 2.961... < 3$ the proof is complete.
\end{proof}
The previous section was about connectivity in $\mathcal{G}_{n,p}$, in this section we have seen that connectivity can be characterised as a monotone increasing property.
Also it was observed that the function $p$ was somehow best possible, by that we mean that modifying it slightly would imply to only have a zero-one law. 
We call such a function $p$ a threshold ( in that case for the connectivity ). 
\newline

More formally, let $\mathcal{Q}$ a monotone increasing property,  in $\mathcal{G}_{n, p}$, we call $\hat{p} = \hat{p}(n)$ a threshold if
\begin{align}
	\mathbb{P}(\mathcal{G}_{n,p} \in \mathcal{Q}) \rightarrow \left\{\begin{array}{rl}
										0 & \text{if } p / \hat{p} \to 0,\\
										1 & \text{if } p / \hat{p} \to \infty.
									 \end{array}
									\right.
\end{align}

Analogously, in $\mathcal{G}_{n, M}$, we call $\hat{M} = \hat{M}(n)$ a threshold if
\begin{align}
	\mathbb{P}(\mathcal{G}_{n,M} \in \mathcal{Q}) \rightarrow \left\{\begin{array}{rl}
										0 & \text{if } M / \hat{M} \to 0,\\
										1 & \text{if } M / \hat{M} \to \infty.
									 \end{array}
									\right.
\end{align}
In fact, thresholds are unique with respect to the multiplication by a positive constant. So for the following, we should denote a threshold for a property as \emph{the} threshold.
\newline
As said in the introduction of this section, the fact that thresholds could be found for many of the properties that where investigated is one of the main reason behind the study of random graphs.
In fact, the following theorem from Bollob\'as and Thomason (TODO : ADD REF )confirms that we can always expect the existence of a threshold if the property investigated is non trivial.
\begin{theorem}
	Every non-trivial monotone graph property has a threshold
\end{theorem}
\begin{proof}
	We consider without loss of generality that $\mathcal{P}$ is a monotone increasing graph property.
	Given $0 < \epsilon < 1$ we define $p:[0,1] \to [0,1]$ such that :
	\begin{equation}
		\mathbb{P}(\mathcal{G}_{n, p} \in \mathcal{P}) = \epsilon
	\end{equation}
	The existence of $p$ is guaranteed from \eqref{eq:QProp} because it is an increasing polynomial in $p$, from 0 to 1.
	Indeed, we know that it is increasing from \eqref{th:QIncr}.
	\newline
	We will show that $p^* = p(\frac{1}{2})$ is a threshold for $\mathcal{P}$ through a coupling argument.
	We take $G_1, G_2, ..., G_k$ independent random variables in $\mathcal{G}_{n,p}$.
	Then we claim that $G_1 \cup G_2 \cup ... \cup G_k$ is distributed as a random variable in $\mathcal{G}_{n, 1 - (1-p)^k}$.
	Which is clear when we observe the following equivalence for $p_1 < p$ and $p_2$.
	\begin{equation}
		1 - p = (1 - p_1)(1-p_2) \iff p = p_1 + p_2 - p_1p_2
	\end{equation}
	The previous equation being satisfied with $p = 1 -(1-p)^k$, $p_1 = 1 - (1-p)^{k-1}$ and $p_2 = p$.
	\newline
	We prove the claim by induction, the initialisation is clearly true, then if we write $G = G_1 \cup ... \cup G_{k-1}$.
	\begin{align}
		\mathbb{P}(G \cup G_k = H) 	&= \mathbb{P}(G=H) + \mathbb{P}(G_k = H) - \mathbb{P}(G \cap G_k = H) \\ 
						&= \mathbb{P}(G=H) + \mathbb{P}(G_k = H) - \mathbb{P}(G = H)\mathbb{P}(G_k = H) 
	\end{align}
	And we can conclude in the same way as in \eqref{th:QIncr}.
	We may now use Bernoulli's inequality \eqref{bernoulli}, $1 - (1-p)^k \leq kp$ to obtain
	\begin{equation}
		\mathbb{G}_{n,1 - (1-p)^k)} \subseteq \mathbb{G}_{n, kp}
	\end{equation}
	and so $\mathbb{G}_{n, kp} \not\in \mathcal{P}$ implies $G_1, G_2, ..., G_k \not\in \mathcal{P}$. 
	We obtain
	\begin{equation}
		\mathbb{P}(\mathbb{G}_{n, kp} \not\in \mathcal{P}) \leq (\mathbb{P}(\mathbb{G}_{n,p}\not\in\mathcal{P}))^k
	\end{equation}
	Let $\omega$ be a function of $n$ growing arbitrarily slowly such that $\lim_{n\to\infty}\omega(n) = \infty$. 
	Suppose also $p^* = p(\frac{1}{2})$ and $k=\omega$, then
	\begin{equation}
		\mathbb{P}(\mathbb{G}_{n, \omega p^*} \not\in \mathcal{P}) \leq 2^{-\omega} = o(1)
	\end{equation}
	On the other hand,
	\begin{equation}
		\frac{1}{2} = \mathbb{P}(\mathbb{G}_{n,p^*} \not\in \mathcal{P}) \leq (\mathbb{P}(\mathbb{G}_{n, \frac{p^*}{\omega}} \not\in \mathcal{P}))^{\omega}
	\end{equation}
	Finally, 
	\begin{equation}
		\mathbb{P}(\mathbb{G}_{n, \frac{p^*}{\omega}} \not \in \mathcal{P}) \geq 2^{-\frac{1}{\omega}} = 1 -o(1)
	\end{equation}
	This proves that $p^*$ is a threshold for $\mathcal{P}$.
\end{proof}

\section{The stability number}\footnote{This section is from \cite{Bondy08}}
Another property of graphs that one might be interested to study is the stability number. The stability number of a graph is the size of the largest set of vertices we can choose in a graph such that no two vertices are adjacent. 
One of the reasons that makes this an interesting property to study is that it is linked to one of the most fundamental property of graphs, $\chi (G)$, the \emph{chromatic number}. Indeed, the chromatic number being the smallest number of colours\footnote{A colouring of a graph is just assigning to each edge a colour. Colours can be thought as "red, green, blue, ..." or as numbers.} that makes a \emph{proper colouring} of a graph. 
That means a colouring on which there are no two adjacent vertices of the same colour. 
We are then led to a similar question than finding the stability number of a graph.
If we denote by $\alpha(G)$ the stability number of a graph, we have the simple lower bound \footnote{ We use this link with the chromatic as a simple motivation for studying the stability number. It is a number which is in fact of great importance in graph theory but on matters that are out of the scope of this report. See for instance Chapter 12 in \cite{Bondy08}.}
\begin{equation}
	\chi(G) \geq \frac{n}{\alpha(G)}
\end{equation}
Before giving a lower bound on the stability number of a graph it might be interesting to denote that the notion of stable set is dual to the notion of clique and is analogous to the notion of perfect matching that concerns the edges.
Although the following theorem will give a bound that is quite tight in $\mathcal{G}_{n, p}$ the problem of finding the actual maximum stable set of a graph is a $NP$-hard problem.
\begin{theorem}
	The stability number of a graph in $\mathcal{G}_{n, p}$, is at most $\lceil 2p^{-1}\log(n)\rceil$.
\end{theorem}
\begin{proof}
	Let $G \in \mathcal{G}_{n,p}$ and $S \subseteq V$ such that $V$ contains $k+1$ vertices.
	Then we have 
	\begin{equation}
		\mathcal{P}(\text{"S is a stable set"}) = (1-p)^{\binom{k+1}{2}  }
	\end{equation}
	as none of the $\binom{k+1}{2}$ possible edges must be selected.
	\newline
	Let's define our random values as follow, $X_S = \mathbbm{1}(\text{" $S$ is a stable set "})$ and
	\begin{equation}
		X_{k+1} = \sum_{\substack{ S \subseteq V \\ |S| = k + 1}} X_S
	\end{equation}
	the random variable counting the number of stable sets of size $k+1$, so what we are investigating here is the rank $\alpha$ such that $X_k = 0, \forall k > \alpha$. Such an $\alpha$ would then be maximal stability number.
	\begin{align}
		\mathbb{E}X_{k+1} &= \sum_{\substack{ S \subseteq V \\ |S| = k + 1}} \mathbb{E} X_S 	
				  = \sum_{\substack{ S \subseteq V \\ |S| = k + 1}} \mathbb{P}(X_S = 1)	\\		
		&= \sum_{\substack{ S \subseteq V \\ |S| = k + 1}} (1-p)^{\binom{k+1}{2}  }		
		= (1-p)^{\binom{k+1}{2}} \sum_{\substack{ S \subseteq V \\ |S| = k + 1}} 1 	\\	
		&= \binom{n}{k+1} (1-p)^{\binom{k+1}{2}} 
	\end{align}
	Now we will use the common inequalities $  \binom{n}{k+1} \leq \frac{n^{k+1}}{(k+1)!} $ and $(1-p) \leq e^{-p}$. 
	And we have
	\begin{align}
		\mathbb{E}X_{k+1} 	&\leq  \frac{n^{k+1}}{(k+1)!} e^{-p \binom{k+1}{2}} = \frac{n^{k+1}}{(k+1)!} e^{-p \frac{k(k+1)}{2}}\\
									     &\leq  \frac{(ne^{-p\frac{k}{2}})^{k+1}}{(k+1)!}
	\end{align}
	So, if we consider $k = \lceil 2p^{-1}\log(n)\rceil \leq 2p^{-1}\log(n)$ we have that $ ne^{-p\frac{k}{2}} \leq 1$.
	We finally obtain 
	\begin{equation}
		\mathbb{E} X_{k+1} \longrightarrow_{n \to \infty} 0
	\end{equation}
	And then $X_{k+1} = 0$ almost surely which proves the theorem.

\end{proof}

\section{The diameter}\footnote{This section uses \cite{Bollob01}}

\begin{definition}
	The \emph{diameter} of a graph is the greatest distance between any pair of vertices. We denote it by diam($G$) and say it is equal to $\infty$ if the graph is not connected.
\end{definition}
It is quite easy to understand that the diameter is a value that is a great importance particularly in applied systems. For instance, the small world phenomena is quite notorious ( and will be discussed later in this report ) but we can also think of optimisation problems in which the fact that two points are far apart might be of great consequences.
This section won't be focused on real world applications of the diameter because as we will see we are studying a model which is not realistic for that. 
Hence we will first discuss some graph theoretic problems and results on the diameter and after giving the main theorem on the diameter we will demonstrate it through several technical lemmas, some of which will be admitted. Finally some corollary will be obtained from the theorem.
\newline
One of the challenging questions in graph theory is estimating the following function
\begin{equation}\label{eq:DDeltaProb}
	n(D, \Delta) = max\{ |G|, \text{diam}(G) \leq D, \Delta(G) \leq \Delta\}
\end{equation}
$n$ is the function that for a fixed diameter $D$ and a fixed maximal degree $\Delta$, gives the graph with a maximal number of vertices that verifies both conditions. This is the kind of problem that is part of \emph{extremal graph theory}.
\newline
For instance if we take $\Delta = 2$ we obtain easily by construction that a graph that maximises the number of vertices with a diameter $D$ is a $(2D+1)$-cycle. Hence, 
\begin{equation}
	n(D, 2) = 2D + 1, \forall D \in \mathbb{N}
\end{equation}
But it is in fact very hard to obtain such a formula for other values of $D$ or $\Delta$.
\newline
If we take a graph of max degree $\Delta$ we observe that there are at most $\Delta (\Delta - 1)^{k-1}$ vertices at distance $k$ from a chosen vertex. It is easily to be convinced of this simply by drawing such a graph. 
From this very simple construction we can obtain the following upper bound
\begin{equation}
	n(D, \Delta) \leq 1 + \Delta \sum_{j=1}^{D}(\Delta - 1)^{j-1} = \frac{\Delta(\Delta - 1)^D - 2}{\Delta - 2} = n_0(D, \Delta)
\end{equation}
$n_0$ is called the Moore bound and a graph for which the Moore bound is best possible is called a Moore graph. 
The \emph{Petersen's graph} is such a graph with parameter $D= 2$ and $\Delta = 3$. (TODO : ADD A DRAWING OF PETERSEN'S GRAPH).
\newline
When $D=2$ explicit constructions of Moore graphs have been found with $\Delta = 2$ (pentagon) and $\Delta = 3$ (Petersen's graph) as we have seen above.
There also exists an explicit construction with $\Delta = 7$, the Hoffman-Singleton graph on 50 vertices.
There might exist a graph with $\Delta = 57$ on 3250 vertices but its existence is still an open-question.
However, it is proved that no other graph of diameter 2 can be a Moore graph, see Hoffman Singleton (TODO: ADD REF).
\newline
In the end of this section we will give a quite good lower bound on $n$, in order to do so, we will see that we can select a probability function $p$ such that the value of the diameter is highly concentrated.
\newline
In the following we will consider that $d = d(n)$ is a natural number (representing the diameter) and $c$ is a positive real number.
\newline
Now let's give some functions that will allow us to make a study of the diameter in random graphs. If we choose $x$ a vertex in a graph, then we define $\Gamma_k(x)$ as the set of vertices at distance $k$ from $x$. And from this we will define $N_k(x)$ as the set of vertices of distance less than or equal to $k$. 
Formally, we have
\begin{equation}
	\Gamma_k(x) = \{v : d(x, v) = k \}
\end{equation}
\begin{equation}
	N_k(x) = \bigcup_{i=1}^k \Gamma_i(x)
\end{equation}
And we can link those with the diameter using, diam$(G) \leq d $ if and only if $N_d(x) = V(G), \forall x$.
\newline
Similarly diam$(G) \geq d $ if and only if $\exists y, N_{d-1}(y) \neq V(G)$.
\newline
Now we will define the probability function that we will use in the following of this section as 
\begin{equation} \label{eq:pdiam}
	p^d n^{d-1} = \log(\frac{n^2}{c}) \quad, \text{  for some } c >0
\end{equation}
In order for $d = d(n)$ to be finite we need \footnote{ See \eqref{eq:pnd}}
\begin{equation}
	\frac{pn}{(\log(n))^3} \longrightarrow \infty
\end{equation}
The aim of this section will be to prove the following theorem.
\begin{theorem}\label{th:diam2}
	Using all previous definitions on $p$, $d$ and $c$. We have,
	\begin{equation}
		\mathbb{P}(\text{diam}(\mathbb{G}_{n, p}) = d) \longrightarrow e^{-\frac{c}{2}}
	\end{equation}	
	\begin{equation}
		\mathbb{P}(\text{diam}(\mathbb{G}_{n,p}) = d + 1) \longrightarrow 1 - e^{-\frac{c}{2}}
	\end{equation}
\end{theorem}
This theorem states that in $\mathcal{G}_{n,p}$ with $p$ defined as in \eqref{eq:pdiam} the diameter is spread on only two values.
As a corollary we clearly have
\begin{corollary}
	Using all previous definitions on $p$, $d$ and $c$. We have,
	\begin{equation}
		\mathbb{P}(\text{diam}(\mathbb{G}_{n,p} \in \{d, d+1\}) \longrightarrow 1
	\end{equation}
\end{corollary}

In fact the number of values that the diameter can take has been fully resolved by Chung and Lu in \cite{ChungLu01}.
\newline
Before proving such a theorem we will need some technical lemmas and assumptions. So we will give here some equations for reference later.
Also 
\begin{equation}
	p (\frac{\log(n)}{n})^{-1} \longrightarrow_{n \to \infty} \infty
\end{equation}
that should not be too surprising as the threshold for connectivity is $\frac{\log(n) + c}{n}$ as shown before.
We may also consider that $p = o(n^{-\frac{1}{2} +\epsilon}), \forall \epsilon > 0$ as it can be shown that otherwise the diameter of $\mathcal{G}_{n,p}$ is lower or equal than 2. One might be interested in what $p(n, d, c)$ or $d(n , p, c)$ look like so here they are
\begin{equation}
	p=n^{\frac{1}{d} - 1}(\log(\frac{n^2}{c}))^\frac{1}{d}
\end{equation}
\begin{align}\label{eq:pnd}
	d &= \frac{1}{\log(pn)}(\log(n) + \log \log (n) + log(2) + \mathcal{O}(\frac{1}{\log(n)}))\\
	  &= \mathcal{O}((1+o(1))\frac{\log(n)}{\log\log(n)})
\end{align}
And finally
\begin{equation}
	p(pn)^{d-2} = o(1)
\end{equation}
The first lemma that we present here gives a tail inequality of $\Gamma_k(x)$ conditionally on some space that we will now define. $\Omega_k \subseteq \mathcal{G}_{n, p}$ is a set of graphs with $a = |\Gamma_{k-1}(x)|$ and $b = |N_{k-1}(x)|$ that satisfy
\begin{align}
 \left\{\begin{array}{rl}
		 \frac{1}{2}(pn)^{k-1} \leq a &\leq \frac{1}{2}(pn)^{k-1} \\
		 			    b &\leq 2(pn)^{k-1}
	 \end{array}
	\right.
\end{align}
\begin{lemma}
	Let $x$ be a fixed vertex.
	\newline
	$1 \leq k = k(n)  \leq d-1$
	\newline
	And $ K = K(n)$ that satisfy $ 6 \leq K \leq \frac{1}{12} \sqrt{pn\frac{1}{\log(n)}}$
	We also define
	\begin{equation}
		\alpha_k = K\sqrt{\frac{\log{n}}{(pn)^k}} , \quad \beta_k = p(pn)^{k-1}, \quad \gamma_k = 2\frac{(pn)^{k-1}}{n} = \frac{2\beta_k}{pn}
	\end{equation}

	Then
	\begin{equation}
		\mathbb{P}(|\gamma_k(x) - apn| \geq (\alpha_k + \beta_k + \gamma_k)apn \quad|\quad \Omega_k) \leq n^{-\frac{K^2}{9}}
	\end{equation}
\end{lemma}

\begin{proof}
	Knowing that we are in the space $\Omega_k$, then the probability that some vertex $y$ is at distance $k$, that is the probability that $y$ is not in $N_{k-1}(x)$ but is connected to $\Gamma_{k-1}(x)$ is 
	\begin{equation}
		p^a = 1 - (1-p)^a
	\end{equation}
	Hence, the random value $|\Gamma_k(x)|$ follows a binomial on $n-b$ elements, with a probability $p_a$.
	In the following inequalities we will assume that $n$ is large enough, this will allow us to do certain inequalities that are not really precise but asymptotically satisfying. Also to make it more easy for the reader we consider that all of these inequalities take place in $\Omega_k$ without writing it explicitly.
	\begin{align}
		|\gamma_k(x) - apn| &\geq (\alpha_k + \beta_k + \gamma_k)apn \\
		 &\geq (\alpha_k + \beta_k)apn + \gamma_k apn \\
		 &\geq (\alpha_k + \beta_k)apn + ap(n-n_k) \\ 
		 &\geq (\alpha_k + \beta_k + 1 - \frac{n_k}{n})apn \\ 
		 &\geq (\alpha_k + \beta_k)apn \geq (\alpha_k + \beta_k)apn_k\\ 
	\end{align}
	From this first sequence of inequalities we managed to remove $\gamma_k$ and we used some $n_k$ that is less than $n$.
	The point in evaluating these inequalities is that we now have
	\begin{align}
		\mathbb{P}(|\gamma_k(x) - apn| \geq (\alpha_k &+ \beta_k + \gamma_k)apn \quad|\quad \Omega_k) \\&\leq \mathbb{P}(|\gamma_k(x) - apn_k| \geq (\alpha_k + \beta_k )apn_k \quad|\quad \Omega_k)
	\end{align}
	Now using $ap -p_a \leq \beta_k ap$ and the triangular inequality we have
	\begin{align}
		&\leq \mathbb{P}(|\gamma_k(x) - p_an_k| \geq \alpha_k apn_k \quad|\quad \Omega_k)\\
		&\leq \mathbb{P}(|\gamma_k(x) - p_an_k| \geq \alpha_k p_an_k \quad|\quad \Omega_k)\\
	\end{align}
	And using Theorem 1.7 \eqref{binomTail} from Bollob\'as (TODO : ADD IT IN THE ANNEX AND PROVE IT, JUST A TAIL INEQ ON BINOM)we have
	\begin{align}
		&\leq \frac{1}{\sqrt{\alpha_k^2p_an_k}}\exp(-\frac{1}{3}\alpha_k^2p_an_k) \\
		&\leq \exp(-\frac{1}{3}\alpha_k^2p_an_k)
	\end{align}
	And using $p_a \geq pa(1-\frac{pa}{2})$ , $a \geq \frac{1}{2}(pn)^{k-1}$ and using $n_k = n-b$ we obtain $p_an_k > \frac{(pn)^k}{3}$ that we insert in the previous inequality that will give us the result expected.
	\begin{align}
		&\leq \exp(-\alpha_k^2\frac{(pn)^k}{9}) = n^{-\frac{K^2}{9}}
	\end{align}
\end{proof}
We will now prove another lemma
\begin{lemma}\label{KLemma}
	Let $K > 12$ a constant and $\alpha_k, \beta_k, \gamma_k, k=1,...,d-1$ as before.
	\newline
	Set 
	\begin{equation}
		\delta_k = \exp(2\sum_{l=1}^{k}(\alpha_l + \beta_l +\gamma_l)) - 1
	\end{equation}
	Then if $n$ is sufficiently large, with probability at least $1-n^{-K-2}$ for every vertex $x$ and every natural number $k, 1\leq k \leq d-1$ we have
	\begin{equation}
		||\Gamma_k(x)| - (pn)^k| \leq \delta_k(pn)^k
	\end{equation}
\end{lemma}

\begin{proof}
	As $\delta_{d-1} \longrightarrow_{n\to\infty} 0$ we may assume that $\delta_{d-1} < \frac{1}{4}$
	For a fixed vertex $x$, we denote by $\Omega_k^*$ the set of graph for which 
	\begin{equation}
		||\Gamma_l(x) - (pn)^l| \leq \delta_l(pn)^l \quad , 0 \leq l \leq k
	\end{equation}
	And it is easy to verify that it is decreasing. Anf if one replaces $|\Gamma_l(x)|$ by $a$ it is clear that we have
	\begin{equation}
		\Omega_k^* \subseteq \Omega_{k-1}^* \subseteq \Omega_k
	\end{equation}
	Now, simply applying Bayes formula ( for the complementary ) we have
	\begin{equation}\label{eq:bayes}
		1 - \mathbb{P}(\Omega_k^*)= 1-\mathbb{P}(\Omega_{k-1}^*)
		+ \mathbb{P}(\Omega_{k-1}^*)\mathbb{P}(||\Gamma_k(x)| - (pn)^k| \leq \delta_k(pn)^k | \Omega_{k-1}^*)
	\end{equation}
	If $G \in \Omega_{k-1}^*$ and $|a| = |\Gamma_{k-1}(x)|$ and by applying the definition of belonging to $\Omega_{k-1}^*$ and multiplying both sides by $pn$ we have 
	\begin{equation}
		|(pn)^k - apn| \leq \delta_{k-1}(pn)^k
	\end{equation}
	And we obtain using the second triangular inequality
	\begin{align}
		\mathbb{P}(\neg\Omega_k^* | \Omega_{k-1}^*) 
		&\leq \mathbb{P}(\Omega_{k-1}^*)^{-1}\mathbb{P}(||\gamma_k(x)| - apn| \geq (\delta_k - \delta_{k-1})(pn)^k | \Omega_k)\\
		&\leq (1 - 2(k-1)n^{-\frac{K^2}{9}})^{-1}\mathbb{P}(||\Gamma_k(x)| - apn| \geq 2(\alpha_k + \beta_k + \gamma_k)(pn)^k | \Omega_k)
	\end{align}
	The last inequality being obtained from the hypothesis of induction and using $(1+x) \leq \exp(x)$. Now using the fact that $apn \leq \frac{3}{2} (pn)^k$ we have
	\begin{align}
		&\leq 2\mathbb{P}(||\Gamma_k(x)| - apn| \geq (\alpha_k + \beta_k + \gamma_k)apn | \Omega_k)\\
		&\leq 2n^{-\frac{K^2}{9}}
	\end{align}
	If we combine the last inequality that is obtained applying the previous lemma with \eqref{eq:bayes} then we have the result.
\end{proof}
\begin{definition}
	For $x$ and $y$ two vertices of $G$, we say that $x$ and $y$ are remote if $y \not\in N_d(x)$.
\end{definition}
\begin{proof}
	From \eqref{KLemma} we can obtain the following equation.
	\begin{equation}
		\mathbb{P}(|N_{d-1}(x)| < \frac{5}{6}(pn)^{d-1}) < n^{-4}
	\end{equation}
	Now we estimate the probability that a vertex $y$ is joined to no vertex in a set $W$ with $|W| \geq \frac{5}{6}(pn)^{d-1}$
	\begin{equation}
	(1-p)^{|W|} \leq \exp(-|W|) \leq \exp(-p|W|) = \exp(-\frac{5}{6}\log(\frac{n^2}{c})) = c^{\frac{5}{6}}n^{-\frac{5}{3}}
	\end{equation}

	Hence, if $x, y, z$ are vertices we have
	\begin{align}
		\mathbb{P}(x&\text{ is remote from $y$ and $z$ }) 						\\	
		&\leq \mathbb{P}(|N_{d-1}(x)|\leq \frac{5}{6} (pn)^{d-1}) 					\\
		&+\mathbb{P}(\{y, z\} \cap N_{d-1}(x) = \emptyset | |N_{d-1}(x)| \geq \frac{5}{6}(pn)^{d-1} )	\\
		&\leq \mathbb{P}(|N_{d-1}(x)|\leq \frac{5}{6} (pn)^{d-1}) 					\\				
		&+(\mathbb{P}(\text{$y$ is not joined to } W = N_{d-1}(x) | W \geq \frac{5}{6} (pn)^{d-1}))^2	\\
		&\leq n^{-4} + c^{\frac{5}{3}}n^{-\frac{10}{3}}							\\
		&\leq n^{-3}n^{-\frac{1}{4}}
	\end{align}
	So, we obtain
	\begin{align}
		\mathbb{P}(\mathcal{G}_{n, p} &\text{ contains two remote vertices pairs sharing a vertex })	\\
			&\leq \sum_x\sum_{(y, z)}\mathbb{P}(\text{ $x$ is remote from $y$ and $z$ })		\\
			&\leq \sum_x \binom{n}{2}n^{-3-\frac{1}{4}} = n\binom{n}{2}n^{-3-\frac{1}{4}}		\\
			&\leq n^{-\frac{1}{4}}
	\end{align}
	The following lemma can be obtained quite easily simply by construction.
	\begin{lemma}
		From $r$ disjoint pair of vertices, there are $2^r$ $r$-tuples of vertices meeting each pair.
	\end{lemma}
	TODO : CHECK FOLLOWING LEMMA
	\begin{lemma}
		The $r$-th factorial moment of $X$ ( $X$ being the number of remote pairs of vertices ) is within $o(1)$ of the expected number of ordered $r$-tuples of disjoint remote pairs.
	\end{lemma}
	If we denote by $\mathbb{F}_r$ the probability that a fixed $r$-tuple consists of vertices remote from each other.
	Then,
	\begin{equation}
		\mathbb{E}_r(X) = \frac{n!}{(n-r)!}2\mathbb{F}_r(1+o(1)) + o(1)
	\end{equation}
	In order to shorten the proof, we admit the following lemma that requires a quite long and technical proof. The proof can be found in \cite{Bollob81}.
	\begin{lemma}
		With probability at least $1-n^{-K}$
		\begin{equation}
			(1-n^{-K})Q_r \leq \mathbb{F}_r \leq (1-n^{-K}) Q_r + n^{-K}
		\end{equation}
		With $Q_r = (\frac{c}{n})^r(1+o(1))$
	\end{lemma}

	
	\begin{equation}
		\mathbb{F}_r = (\frac{c}{n})^r(1+o(1))
	\end{equation}
	And we can obtain the asymptotical estimate
	\begin{equation}
		\mathbb{E}_r(X) = n^r2^{-r}(\frac{c}{n})^r(1+o(1)) + o(1)
	\end{equation}
	Using the following theorem 
	\begin{theorem}\footnote{See \eqref{th:factPois} for a proof}
		\begin{align}
			\lim_{n\to\infty} \mathbb{E}_r(X_n) &- \lambda^r = 0 \\
					&\implies X \longrightarrow_d \mathcal{P}_{\lambda}
		\end{align}
	\end{theorem}
	Then we have that $X$ converges in distribution to Poisson law of parameter $\frac{c}{2}$.
	\newline
	We can then obtain 
	\begin{equation}\label{eq:diamcv}
		\mathbb{P}(X=0) = \mathbb{P}(\text{diam}(G) \leq d) \longrightarrow e^{-\frac{c}{2}}
	\end{equation}
	that proves the first part of the theorem. We can also prove the case with $d=1$ that gives
	\begin{equation}
		\mathbb{P}(\text{diam}(\mathbb{G}_{n,p}) \leq 1) = \mathbb{P}(\mathbb{G}_{n,p} = K_n) = p^{\binom{n}{2}} \longrightarrow 0
	\end{equation}
	And to finish the proof we need to consider the two following cases
	\begin{equation}
		p^{d-1}n^{d-2} = \log(\frac{n^2}{c_1(n)})
	\end{equation}
	And in that case we have $c_1 \longrightarrow \infty$.
	\begin{equation}
		\mathbb{P}(\text{diam}(\mathbb{G}_{n,p}) \leq d+1) = e^{-\frac{c_1}{2}} \longrightarrow 0
	\end{equation}
	If we now consider
	\begin{equation}
		p^{d+1}n^d = \log(\frac{n^2}{c_2(n)})
	\end{equation}
	we obtain $c_2 \longrightarrow 0$ which gives
	\begin{equation}
		\mathbb{P}(\text{diam}(\mathbb{G}_{n,p}) \leq d+1) = e^{-\frac{c_2}{2}} \longrightarrow 1
	\end{equation}
	Finally, if we combine the last result with \eqref{eq:diamcv} it is clear that the proof if complete.
\end{proof}
	To end this section we present two theorems that are much easier to prove with a similar flavor to the previous one.
	\begin{theorem}\label{th:diam2}
	Suppose 
	\begin{equation}
		i) \quad p^2n - 2\log(n) \longrightarrow \infty
	\end{equation}
	\begin{equation}
		ii) \quad n^2(1-p) \longrightarrow \infty
	\end{equation}
	Then almost every graph in $\mathcal{G}_p$ has diameter 2.
\end{theorem}

\begin{proof}
	\begin{equation}
		\mathbb{P}(\text{dist}(x, y) > 2) = (1-p^2)^{n-2}
	\end{equation}
	as it is the probability that two vertices $x$ and $y$ are not connected by a path of length two.
	\newline
	Then using the the first moment method.
	\begin{align}
		\mathbb{E}&(\text{ pairs not connected by a path of length 2})	\\
				&= \binom{n}{2}(1-p^2)^{n-2} \geq \mathbb{P}(\text{diam}(\mathbb{G}_{n,p}) > 2)
	\end{align}
	As from $i)$ the LHS converges to zero, we are almost sure that no graph is of diameter more than 2 and then we just have to prove that there is almost no graph of diameter 1.
	A graph of diameter 1 being a complete graph we have
	\begin{align}
		\mathbb{P}(\text{diam}(\mathbb{G}_{n,p}) = 1) = \mathbb{P}(\mathbb{G}_{n,p} = K_n) 	
				= p^{\binom{n}{2}} &\longrightarrow 0				\\
		\text{iff  } \log p^{\binom{n}{2}} &\longrightarrow -\infty			\\
			   \text{iff  } n^2 \log p &\longrightarrow -\infty			\\
			    \text{iff  } n^2 (1-p) &\longrightarrow +\infty			
	\end{align}	
\end{proof}
And simply if we remember the previous theorem \eqref{th:linkMP} linking $\mathcal{G}_{n,p}$ and $\mathcal{G}_{n,M}$ we obtain the following corollary

\begin{corollary}
	If $M=M(n) < \binom{n}{2}$ satisfies 
	\begin{equation}
		\frac{2M^2}{n^3} - \log(n) \longrightarrow \infty
	\end{equation}
	Then almost every graph in $\mathcal{G}_{n, M}$ is of diameter 2.
\end{corollary}
\begin{proof}
	The first condition makes that we are not studying a complete graph then the diameter is not 1.
	And we have the proof simply using \eqref{th:linkMP} with $pN = M$ and combining it with the previous theorem \eqref{th:diam2} we have the result.
\end{proof}

Now that we know that the diameter is spread on two values we are interested in restricting it on only one value. 
We may observe that theorem \eqref{th:diam2} gives us enough information to do so.
Indeed, we see that if we forced $c \to 0$ then the diameter would be $d$. This would translate in \eqref{eq:pdiam} as
\begin{equation}
	p^dn^{d-1} - 2\log(n) \longrightarrow \infty
\end{equation}
But this restriction is not sufficient because the values of the diameter might be smaller than $d$ then we will need to make sure that the probability that the diameter is $d-1$ goes to 0 which we could do forcing $c \to \infty$.
In the same fashion as previously this would translate as
\begin{equation}
	p^{d-1}n^{d-2} - 2 \log(n) \longrightarrow -\infty
\end{equation}

This informal reasoning gives motivation for the following corollary of \eqref{th:diam2} that we will now formally prove. 
\footnote{In fact it is a immediate consequence of the last part of the proof of \eqref{th:diam2} but we will prove it only assuming the theorem itself.}
\begin{corollary}\label{th:aediam}
	Suppose $d = d(n) \geq 3$ and $p = p(n)$ satisfy
	\begin{equation}
		\frac{\log(n)}{d} - 3\log\log n \to \infty
	\end{equation}
	\begin{equation}
		p^dn^{d-1} - 2\log(n) \longrightarrow \infty \quad \text{and} \quad
		p^{d-1}n^{d-2} - 2 \log(n) \longrightarrow -\infty
	\end{equation}
	Then almost every $\mathbb{G}_{n,p}$ has diameter $d$.
\end{corollary}
\begin{proof}
	Let $K_1$ and $K_2$ be positive constants and define $0<p_1<p_2<1$ by
	\begin{equation}
		p_1^{d+1}n^d = \log(\frac{n^2}{K_1}) \quad \text{and} \quad p_2^{d}n^{d-1} = \log(\frac{n^2}{K_2})	
	\end{equation}
	Then 
	\begin{equation}
		\limsup_{n \to \infty} \mathbb{P}(\text{diam}\mathbb{G}_{n,p} \geq d+1 )
		\leq  \limsup_{n \to \infty} \mathbb{P}(\text{diam}\mathbb{G}_{n,p_1} \geq d+1 ) = 1 - e^{-\frac{K_1}{2}}
	\end{equation}
	\begin{equation}
		\limsup_{n \to \infty} \mathbb{P}(\text{diam}\mathbb{G}_{n,p} \leq d-1 )
		\leq  \limsup_{n \to \infty} \mathbb{P}(\text{diam}\mathbb{G}_{n,p_2} \geq d-1 ) = e^{-\frac{K_2}{2}}
	\end{equation}
	As we can choose an arbitrary small $K_1$ and an arbitrarily large $K_2$ the assertion follows.
\end{proof}


Now, going back to the degree-diameter problem defined in \eqref{eq:DDeltaProb}, which is of finding the largest graph with fixed diameter and maximal degree.
As we already have the Moore upper bound which is best possible, we are interested in finding a lower bound, and maybe hope that it would be close from Moore's bound in order to obtain precise estimate of $n(D, \Delta)$.
To obtain such a bound here we will make use of the probabilistic method by sampling on an appropriate graph space (with known diameter and max degree), we will show that almost surely a specified property doesn't appear (having less that a specified number of vertices).
\newline

In other words, by choosing an appropriate function $p$ of $n$ we can obtain some estimates which are almost surely true on $D$ and $\Delta$. Thus $n$ would almost surely be a lower bound of the degree-diameter problem.
\newline
In order to have a relation between $n$, $p$ and $\Delta$ we admit the following result from \cite{Bollob01}.
\begin{theorem}\label{th:deltap}
	If $\frac{pn}{\log n} \to \infty$, then almost every graph in $\mathcal{G}_{n,p}$ satisfies 
	\begin{equation}
		\Delta(\mathbb{G}_{n,p} = (1+o(1))pn
	\end{equation}
\end{theorem}
We can obtain the following result :
\begin{theorem}
	Suppose $0<\epsilon <1$ and the sequence $(D_k), (\Delta_k)$ are such that 
	\begin{equation}
		D_k^4 \leq \Delta_k \quad \text{and} \quad D_k \to \infty
	\end{equation}
	Then if $k$ is sufficiently large,
	\begin{equation}
		n(D_k, \Delta_k) \geq \frac{((1-\epsilon)\Delta_k)^{D_k}}{2D_k\log \Delta_k}
	\end{equation}
\end{theorem}
\begin{proof}
	As discussed before, to obtain such a proof we need to find the good function $p$ of $n$, luckily we may also choose to define $p$ on specific values of $n$ in order for the following argument to be true. 
	So, we set 
	\begin{equation}
		n_k = \lceil \frac{((1-\epsilon)\Delta_k)^{D_k}}{2D_k\log \Delta_k} \rceil
	\end{equation}
	\begin{equation}
		p_k = n_k^{\frac{1}{D_k} -1 }(2\log(n_k) + \log\log(n_k))^{1/D_k}
	\end{equation}
	From the previous corollary \eqref{th:aediam}, almost every graph in $\mathcal{G}_{n_k, p_k}$ has diameter ( at most ) $D_k$.
	From \eqref{th:deltap}, almost every graph in $\mathcal{G}_{n_k,p_k}$ has maximal degree about $p_kn_k$. 
	\begin{align}
		\Delta(\mathbb{G}_{n_k,p_k}) 	&=(1+o(1))n_kp_k \\
						&= (1+o(1))n_k^{1/D_k}(2\log n_k + \log\log n_k)^{1/D_k}	\\
						&= (1+o(1))\lceil{\frac{(1-\epsilon)\Delta_k}{(2D_k\log(\Delta_k))^{1/D_k}}}\rceil(2\log n_k +  \log\log n_k)^{1/D_k}\\	
						&\leq \frac{(1+o(1))(1-\epsilon) \Delta_k}{(2D_k \log\Delta_k)^{1/D_k}} (2D_k\log((1-\epsilon)\Delta_k))^{1/D_k} \\   
						&\leq (1+o(1))(1-\epsilon)\Delta_k \leq (1-\epsilon)\Delta_k \\
						&< \Delta_k	
	\end{align}	
	Which gives,
	\begin{equation}
		n(D_k, \Delta_k)\geq n_k \geq \frac{((1-\epsilon)\Delta_k)^{D_k}}{2D_k\log \Delta_k} 
	\end{equation}
\end{proof}
As a strengthening of this result, Bollob\'as \cite{BollobExtr} conjectured that for each $\epsilon > 0$, it should be the case that $$n(D, \Delta) > (1-\epsilon)\Delta^D$$ if $\Delta$ and $D$ are sufficiently large.
\newline
A quite recent survey on the degree-diameter problem can be found in \cite{degreeDiam}.

